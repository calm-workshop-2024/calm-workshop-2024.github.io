<!DOCTYPE html>
<html lang="en"><head>

    <meta name="generator" content="Hugo 0.135.0">
    <meta name="date" content="2024-09-27T13:17:08Z">
    
    <meta charset="utf-8">
    <meta name="HandheldFriendly" content="True">
    <meta name="MobileOptimized" content="320">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <meta name="referrer" content="no-referrer">
    
    <meta name="author" content="Felix Leeb, Ching Lam Choi, Luigi Gresele, Josef Valvoda, Andrei Nicolicioiu, Xiusi Li, Patrik Reizinger, Sophie Xhonneux, Haoxuan Li, Mengyue Yang, Bernhard Schölkopf, Dhanya Sridhar" />
    <meta name="description" content="First Workshop on Causality and Large Models (C♥️LM) @ NeurIPS 2024" />
    <meta name="keywords" content="workshop, causal representation learning, large models, foundation models" />
    
    <title>C♥️LM @ NeurIPS 2024 | Accepted Papers</title>
    
    <meta property="og:title" content="Accepted Papers" />
    <meta property="og:type" content="website" />
    <meta property="og:description" content="First Workshop on Causality and Large Models (C♥️LM) @ NeurIPS 2024" />
    
    <meta name="twitter:title" content="" />
    
    <link rel="preconnect" href="https://fonts.googleapis.com">
    <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
    <link href="https://fonts.googleapis.com/css2?family=Lato:ital,wght@0,300;0,400;1,300&display=swap" rel="stylesheet"> 
    
    <link rel="canonical" href="https://calm-workshop-2024.github.io/accepted-papers/">
    <link rel="stylesheet" href="https://calm-workshop-2024.github.io/styles.css">
    
    <link rel="apple-touch-icon" sizes="180x180" href="https://calm-workshop-2024.github.io/apple-touch-icon.png">
    <link rel="icon" type="image/png" sizes="32x32" href="https://calm-workshop-2024.github.io/favicon-32x32.png">
    <link rel="icon" type="image/png" sizes="16x16" href="https://calm-workshop-2024.github.io/favicon-16x16.png">
    <link rel="manifest" href="https://calm-workshop-2024.github.io/site.webmanifest">

</head><body><section id="header">

    <div id="logo-container">
        <div id="title-inner-container">
            <a href="https://calm-workshop-2024.github.io/"><img src="https://calm-workshop-2024.github.io/logo.png" id="logo" width="180px"></a>
        </div>
    </div>

    <div id="title-container">
        <div id="title-inner-container">
            <div class="supertitle">C♥️LM: First Workshop on</div>
            <div class="title"><a href="https://calm-workshop-2024.github.io/">Causality and Large Models</a></div>
            <div class="subtitle">December 14 @ NeurIPS 2024 in East Hall C</div>
        </div>
    </div>

    <br>

    <div id="navigation">
        <ul>
        
            <li><strong><a href="https://calm-workshop-2024.github.io/about">About</a></strong></li>
        
            <li><strong><a href="https://calm-workshop-2024.github.io/schedule">Schedule</a></strong></li>
        
            <li><strong><a href="https://calm-workshop-2024.github.io/invited-speakers">Invited Speakers</a></strong></li>
        
            <li><strong><a href="https://calm-workshop-2024.github.io/accepted-papers">Accepted Papers</a></strong></li>
        
            <li><strong><a href="https://calm-workshop-2024.github.io/call-for-papers">Call for Papers</a></strong></li>
        
            <li><strong><a href="https://calm-workshop-2024.github.io/team">Our Team</a></strong></li>
        
      </ul>
    </div>

</section><section id="content">
        
    <h1 id="accepted-papers">Accepted Papers</h1>
<h2 id="oral-presentation">Oral Presentation</h2>
<!-- # Accepted Papers -->
<ul>
<li>
<p><a href="https://openreview.net/forum?id=FcVnIBYbkW"><strong>From Causal to Concept-Based Representation Learning</strong></a></p>
</li>
<li>
<p><a href="https://openreview.net/forum?id=pAWrQEdlxq"><strong>Using Relational and Causality Context for Tasks with Specialized Vocabularies that are Challenging for LLMs</strong></a></p>
</li>
<li>
<p><a href="https://openreview.net/forum?id=T0gy6Lb72A"><strong>Causally Testing Gender Bias in LLMs: A Case Study on Occupational Bias</strong></a></p>
</li>
<li>
<p><a href="https://openreview.net/forum?id=3fzCBL6ar7"><strong>Causal Order: The Key to Leveraging Imperfect Experts in Causal Inference</strong></a></p>
</li>
</ul>
<h2 id="poster-presentation">Poster Presentation</h2>
<ul>
<li>
<p><a href="https://openreview.net/forum?id=MnzctRss9f"><strong>CausalQuest: Collecting Natural Causal Questions for AI Agents</strong></a></p>
</li>
<li>
<p><a href="https://openreview.net/forum?id=IGSDECEKt8"><strong>A Causal Perspective in Brainwave Foundation Models</strong></a></p>
</li>
<li>
<p><a href="https://openreview.net/forum?id=UkSY1BcdaD"><strong>Interactive Semantic Interventions for VLMs: A Causality-Inspired Investigation of VLM Failures</strong></a></p>
</li>
<li>
<p><a href="https://openreview.net/forum?id=USbL3Etk4G"><strong>Estimating Effects of Tokens in Preference Learning</strong></a></p>
</li>
<li>
<p><a href="https://openreview.net/forum?id=gDXAde7AC7"><strong>Competence-Based Analysis of Language Models</strong></a></p>
</li>
<li>
<p><a href="https://openreview.net/forum?id=kbmGbm2L1P"><strong>CausalBench: A Comprehensive Benchmark for Evaluating Causal Reasoning Capabilities of Large Language Models</strong></a></p>
</li>
<li>
<p><a href="https://openreview.net/forum?id=uEOUvr2xVo"><strong>Reasoning with a Few Good Cross-Questions Greatly Enhances Causal Event Attribution in LLMs</strong></a></p>
</li>
<li>
<p><a href="https://openreview.net/forum?id=2gENrLD5nn"><strong>LLM-initialized Differentiable Causal Discovery</strong></a></p>
</li>
<li>
<p><a href="https://openreview.net/forum?id=ldnKzNQ5l0"><strong>Counterfactual Causal Inference in Natural Language with Large Language Models</strong></a></p>
</li>
<li>
<p><a href="https://openreview.net/forum?id=qTTSaRBVYI"><strong>From Correlation to Causation: Understanding Climate Change through ML and LLM Inquiries</strong></a></p>
</li>
<li>
<p><a href="https://openreview.net/forum?id=VVxxGUIGix"><strong>Are UFOs Driving Innovation? The Illusion of Causality in Large Language Models</strong></a></p>
</li>
<li>
<p><a href="https://openreview.net/forum?id=n4AvrD8kl5"><strong>Evaluating Interventional Reasoning Capabilities of Large Language Models</strong></a></p>
</li>
<li>
<p><a href="https://openreview.net/forum?id=3sqBg9SI6Y"><strong>CodeSCM: Causal Analysis for Multi-Modal Code Generation</strong></a></p>
</li>
<li>
<p><a href="https://openreview.net/forum?id=S4pwjKmLGR"><strong>Counterfactual Token Generation in Large Language Models</strong></a></p>
</li>
<li>
<p><a href="https://openreview.net/forum?id=lXVVpoW2CJ"><strong>Hypothesizing Missing Causal Variables with LLMs</strong></a></p>
</li>
<li>
<p><a href="https://openreview.net/forum?id=EGWrfirmIM"><strong>Investigating Causal Reasoning in Large Language Models</strong></a></p>
</li>
<li>
<p><a href="https://openreview.net/forum?id=wqir4sG2Bc"><strong>CausalGraph2LLM: Evaluating LLMs for Causal Queries</strong></a></p>
</li>
<li>
<p><a href="https://openreview.net/forum?id=lZLwoWXVWy"><strong>On Incorporating Prior Knowledge Extracted from Pre-trained Language Models into Causal Discovery</strong></a></p>
</li>
<li>
<p><a href="https://openreview.net/forum?id=AqRQvOINf8"><strong>Leveraging LLM-Generated Structural Prior for Causal Inference with Concurrent Causes</strong></a></p>
</li>
<li>
<p><a href="https://openreview.net/forum?id=xzeiWXOxBu"><strong>Causal Reasoning in Large Language Models: A Knowledge Graph Approach</strong></a></p>
</li>
<li>
<p><a href="https://openreview.net/forum?id=3hdNJr8IR4"><strong>Are Police Biased? An NLP Approach</strong></a></p>
</li>
<li>
<p><a href="https://openreview.net/forum?id=dgeWznoY8h"><strong>On LLM Augmented AB Experimentation</strong></a></p>
</li>
<li>
<p><a href="https://openreview.net/forum?id=6Hgd2pmwcN"><strong>Causal Interventions on Causal Paths: Mapping GPT-2&rsquo;s Reasoning From Syntax to Semantics</strong></a></p>
</li>
<li>
<p><a href="https://openreview.net/forum?id=vnFtU3fO9h"><strong>Teaching Transformers Causal Reasoning through Axiomatic Training</strong></a></p>
</li>
<li>
<p><a href="https://openreview.net/forum?id=S4X1P4QOFo"><strong>Causal World Representation in the GPT Model</strong></a></p>
</li>
<li>
<p><a href="https://openreview.net/forum?id=Wmg7IZl32b"><strong>Can large language models reason about causal relationships in multimodal time series data?</strong></a></p>
</li>
</ul>


    </section>
<div id="footer">
    Made with <a href="https://gohugo.io/">Hugo</a> and hosted on <a href="TODO">GitHub</a>.
</div>


</body>

</html>