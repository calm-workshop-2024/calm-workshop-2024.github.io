<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Home on </title>
    <link>https://calm-workshop-2024.github.io/</link>
    <description>Recent content in Home on </description>
    <generator>Hugo</generator>
    <language>en</language>
    <atom:link href="https://calm-workshop-2024.github.io/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>About</title>
      <link>https://calm-workshop-2024.github.io/about/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://calm-workshop-2024.github.io/about/</guid>
      <description>&lt;h2 id=&#34;about-the-workshop&#34;&gt;About the workshop&lt;/h2&gt;&#xA;&lt;p&gt;The remarkable capabilities and accessibility of recent large models, also known as “foundation models,” have sparked significant interest and excitement in the research community and beyond. In particular, large pre-trained generative models have demonstrated remarkable competencies in understanding and generating human-like text despite being trained on largely unstructured data using relatively simple self-supervised learning objectives. This raises the question: (A) &lt;em&gt;Why do such large models work so well?&lt;/em&gt;&lt;/p&gt;</description>
    </item>
    <item>
      <title>Accepted Papers</title>
      <link>https://calm-workshop-2024.github.io/accepted-papers/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://calm-workshop-2024.github.io/accepted-papers/</guid>
      <description>&lt;h1 id=&#34;accepted-papers&#34;&gt;Accepted Papers&lt;/h1&gt;&#xA;&lt;h2 id=&#34;oral-presentation&#34;&gt;Oral Presentation&lt;/h2&gt;&#xA;&lt;!-- # Accepted Papers --&gt;&#xD;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&#xA;&lt;p&gt;&lt;a href=&#34;https://openreview.net/forum?id=FcVnIBYbkW&#34;&gt;&lt;strong&gt;From Causal to Concept-Based Representation Learning&lt;/strong&gt;&lt;/a&gt;&lt;/p&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;&#xA;&lt;p&gt;&lt;a href=&#34;https://openreview.net/forum?id=pAWrQEdlxq&#34;&gt;&lt;strong&gt;Using Relational and Causality Context for Tasks with Specialized Vocabularies that are Challenging for LLMs&lt;/strong&gt;&lt;/a&gt;&lt;/p&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;&#xA;&lt;p&gt;&lt;a href=&#34;https://openreview.net/forum?id=T0gy6Lb72A&#34;&gt;&lt;strong&gt;Causally Testing Gender Bias in LLMs: A Case Study on Occupational Bias&lt;/strong&gt;&lt;/a&gt;&lt;/p&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;&#xA;&lt;p&gt;&lt;a href=&#34;https://openreview.net/forum?id=3fzCBL6ar7&#34;&gt;&lt;strong&gt;Causal Order: The Key to Leveraging Imperfect Experts in Causal Inference&lt;/strong&gt;&lt;/a&gt;&lt;/p&gt;&#xA;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h2 id=&#34;poster-presentation&#34;&gt;Poster Presentation&lt;/h2&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&#xA;&lt;p&gt;&lt;a href=&#34;https://openreview.net/forum?id=MnzctRss9f&#34;&gt;&lt;strong&gt;CausalQuest: Collecting Natural Causal Questions for AI Agents&lt;/strong&gt;&lt;/a&gt;&lt;/p&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;&#xA;&lt;p&gt;&lt;a href=&#34;https://openreview.net/forum?id=IGSDECEKt8&#34;&gt;&lt;strong&gt;A Causal Perspective in Brainwave Foundation Models&lt;/strong&gt;&lt;/a&gt;&lt;/p&gt;</description>
    </item>
    <item>
      <title>Call for Papers</title>
      <link>https://calm-workshop-2024.github.io/call-for-papers/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://calm-workshop-2024.github.io/call-for-papers/</guid>
      <description>&lt;h1 id=&#34;call-for-papers&#34;&gt;Call for Papers&lt;/h1&gt;&#xA;&lt;h2 id=&#34;important-dates&#34;&gt;Important Dates&lt;/h2&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;strong&gt;Paper submission deadline: September 23, 2024, AoE&lt;/strong&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Notification to authors: October 09, 2024, AoE&lt;/strong&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Camera-ready version: December 7, 2024&lt;/strong&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Workshop Date: December 14, 2024&lt;/strong&gt;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h2 id=&#34;submit-your-paper-on-openreviewhttpsopenreviewnetgroupidneuripscc2024workshopcalm&#34;&gt;Submit your paper on &lt;a href=&#34;https://openreview.net/group?id=NeurIPS.cc/2024/Workshop/CALM&#34;&gt;OpenReview&lt;/a&gt;&lt;/h2&gt;&#xA;&lt;p&gt;Our workshop aims to explore the many exciting synergies between causality and large models. We identify four main directions to cover in our workshop:&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&#xA;&lt;p&gt;Causality &lt;em&gt;for&lt;/em&gt; large models: Applying ideas from causality to improve large models.&lt;/p&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;&#xA;&lt;p&gt;Causality &lt;em&gt;with&lt;/em&gt; large models: Leveraging large models to improve causal inference.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Call for Reviewers</title>
      <link>https://calm-workshop-2024.github.io/call-for-reviewers/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://calm-workshop-2024.github.io/call-for-reviewers/</guid>
      <description>&lt;h1 id=&#34;call-for-reviewers&#34;&gt;Call for Reviewers&lt;/h1&gt;&#xA;&lt;h2 id=&#34;sign-up-to-be-a-reviewer-herehttpsformsglerby9yb8ufwbpxxjc9&#34;&gt;Sign up to be a reviewer &lt;a href=&#34;https://forms.gle/rby9yB8ufWBPXxJC9&#34;&gt;here&lt;/a&gt;&lt;/h2&gt;&#xA;&lt;p&gt;We plan to have 2 papers per reviewer (with a maximum of 3 papers), each paper being 4-6 pages. Expected reviewing period: late September.&#xA;We will come back with an Openreview reviewer invitation so please fill the form above with an email associated with your Openreview account.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Formatting Instructions</title>
      <link>https://calm-workshop-2024.github.io/formatting-instructions/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://calm-workshop-2024.github.io/formatting-instructions/</guid>
      <description>&lt;h1 id=&#34;formatting-instructions&#34;&gt;Formatting Instructions&lt;/h1&gt;&#xA;&lt;h2 id=&#34;style--author-instructions&#34;&gt;Style &amp;amp; Author Instructions&lt;/h2&gt;&#xA;&lt;p&gt;Submissions should be formatted using our latex style files (available &lt;a href=&#34;https://github.com/calm-workshop-2024/calm-workshop-2024.github.io/raw/main/style_files/neurips_2024_calm.zip&#34;&gt;here&lt;/a&gt;). Papers should be submitted as a PDF file and should be 4-6 pages in length, including all main results, figures, and tables. Appendices containing additional details are allowed, but reviewers are not expected to take this into account.&lt;/p&gt;&#xA;&lt;p&gt;The workshop will not have proceedings (it will not be archival), which means you can submit the same or extended work as a publication to other venues after the workshop.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Important Dates</title>
      <link>https://calm-workshop-2024.github.io/dates/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://calm-workshop-2024.github.io/dates/</guid>
      <description>&lt;h2 id=&#34;important-dates&#34;&gt;Important Dates&lt;/h2&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;strong&gt;Paper submission deadline: September 23, 2024, AoE&lt;/strong&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Notification to authors: October 09, 2024, AoE&lt;/strong&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Camera-ready version: December 7, 2024&lt;/strong&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Workshop Date: December 14, 2024&lt;/strong&gt;&lt;/li&gt;&#xA;&lt;/ul&gt;</description>
    </item>
    <item>
      <title>Invited Speakers</title>
      <link>https://calm-workshop-2024.github.io/invited-speakers/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://calm-workshop-2024.github.io/invited-speakers/</guid>
      <description>&lt;h1 id=&#34;invited-speakers&#34;&gt;Invited Speakers&lt;/h1&gt;&#xA;&lt;div class=&#34;list-of-people&#34;&gt;&#xD;&#xA;    &lt;div class=&#34;person&#34;&gt;&#xD;&#xA;        &lt;td&gt;&lt;img src=&#34;https://calm-workshop-2024.github.io/speaker1_tobias.jpg&#34;&gt;&lt;/td&gt;&#xD;&#xA;        &lt;td&gt;&lt;a href=&#34;https://cicl.stanford.edu/member/tobias_gerstenberg/&#34;&gt;Tobias Gerstenberg &lt;br&gt;(Stanford University)&lt;/a&gt;&lt;/td&gt;&#xD;&#xA;    &lt;/div&gt;&#xD;&#xA;    &lt;div class=&#34;person&#34;&gt;&#xD;&#xA;        &lt;td&gt;&lt;img src=&#34;https://calm-workshop-2024.github.io/speaker2_jane.jpeg&#34;&gt;&lt;/td&gt;&#xD;&#xA;        &lt;td&gt;&lt;a href=&#34;https://www.janexwang.com/&#34;&gt;Jane X. Wang&lt;br&gt;(DeepMind)&lt;/a&gt;&lt;/td&gt;&#xD;&#xA;    &lt;/div&gt;&#xD;&#xA;    &lt;div class=&#34;person&#34;&gt;&#xD;&#xA;        &lt;td&gt;&lt;img src=&#34;https://calm-workshop-2024.github.io/speaker3_claudia.jpeg&#34;&gt;&lt;/td&gt;&#xD;&#xA;        &lt;td&gt;&lt;a href=&#34;https://claudiajshi.com/&#34;&gt;Claudia Shi&lt;br&gt;(Columbia University)&lt;/a&gt;&lt;/td&gt;&#xD;&#xA;    &lt;/div&gt;&#xD;&#xA;    &lt;div class=&#34;person&#34;&gt;&#xD;&#xA;        &lt;td&gt;&lt;img src=&#34;https://calm-workshop-2024.github.io/speaker4_victor.jpeg&#34;&gt;&lt;/td&gt;&#xD;&#xA;        &lt;td&gt;&lt;a href=&#34;http://victorveitch.com/&#34;&gt;Victor Veitch&lt;br&gt;(University of Chicago &amp; Google DeepMind)&lt;/a&gt;&lt;/td&gt;&#xD;&#xA;    &lt;/div&gt;&#xD;&#xA;        &lt;div class=&#34;person&#34;&gt;&#xD;&#xA;        &lt;td&gt;&lt;img src=&#34;https://calm-workshop-2024.github.io/speaker5_amit.jpeg&#34;&gt;&lt;/td&gt;&#xD;&#xA;        &lt;td&gt;&lt;a href=&#34;https://amitsharma.in//&#34;&gt;Amit Sharma&lt;br&gt;(Microsoft Research)&lt;/a&gt;&lt;/td&gt;&#xD;&#xA;    &lt;/div&gt;&#xD;&#xA;        &lt;div class=&#34;person&#34;&gt;&#xD;&#xA;        &lt;td&gt;&lt;img src=&#34;https://calm-workshop-2024.github.io/speaker6_elias.jpeg&#34;&gt;&lt;/td&gt;&#xD;&#xA;        &lt;td&gt;&lt;a href=&#34;https://causalai.net/&#34;&gt;Elias Bareinboim&lt;br&gt;(Columbia University)&lt;/a&gt;&lt;/td&gt;&#xD;&#xA;    &lt;/div&gt;&#xD;&#xA;&lt;/div&gt;&#xD;&#xA;&lt;h1 id=&#34;panellists&#34;&gt;Panellists&lt;/h1&gt;&#xA;&lt;div class=&#34;list-of-people&#34;&gt;&#xD;&#xA;    &lt;div class=&#34;person&#34;&gt;&#xD;&#xA;        &lt;td&gt;&lt;img src=&#34;https://calm-workshop-2024.github.io/panellist1_maria.png&#34;&gt;&lt;/td&gt;&#xD;&#xA;        &lt;td&gt;&lt;a href=&#34;https://maria-antoniak.github.io/&#34;&gt;Maria Antoniak&lt;br&gt;(Allen Institute for AI)&lt;/a&gt;&lt;/td&gt;&#xD;&#xA;    &lt;/div&gt;&#xD;&#xA;    &lt;div class=&#34;person&#34;&gt;&#xD;&#xA;        &lt;td&gt;&lt;img src=&#34;https://calm-workshop-2024.github.io/panellist2_gp.jpeg&#34;&gt;&lt;/td&gt;&#xD;&#xA;        &lt;td&gt;&lt;a href=&#34;https://sites.google.com/view/giambattista-parascandolo/home/&#34;&gt;Giambattista Parascandolo&lt;br&gt;(OpenAI)&lt;/a&gt;&lt;/td&gt;&#xD;&#xA;    &lt;/div&gt;&#xD;&#xA;    &lt;div class=&#34;person&#34;&gt;&#xD;&#xA;        &lt;td&gt;&lt;img src=&#34;https://calm-workshop-2024.github.io/panellist3_atticus.jpeg&#34;&gt;&lt;/td&gt;&#xD;&#xA;        &lt;td&gt;&lt;a href=&#34;https://atticusg.github.io/&#34;&gt;Atticus Geiger&lt;br&gt;(Pr(Ai)²R Group)&lt;/a&gt;&lt;/td&gt;&#xD;&#xA;    &lt;/div&gt;&#xD;&#xA;    &lt;!-- &lt;div class=&#34;person&#34;&gt;&#xD;&#xA;        &lt;td&gt;&lt;img src=&#34;https://calm-workshop-2024.github.io/panellist4_charlotte.webp&#34;&gt;&lt;/td&gt;&#xD;&#xA;        &lt;td&gt;&lt;a href=&#34;https://aimm.epfl.ch/&#34;&gt;Charlotte Bunne&lt;br&gt;(EPFL)&lt;/a&gt;&lt;/td&gt;&#xD;&#xA;    &lt;/div&gt; --&gt;&#xD;&#xA;    &lt;div class=&#34;person&#34;&gt;&#xD;&#xA;        &lt;td&gt;&lt;img src=&#34;https://calm-workshop-2024.github.io/speaker6_elias.jpeg&#34;&gt;&lt;/td&gt;&#xD;&#xA;        &lt;td&gt;&lt;a href=&#34;https://causalai.net/&#34;&gt;Elias Bareinboim&lt;br&gt;(Columbia University)&lt;/a&gt;&lt;/td&gt;&#xD;&#xA;    &lt;/div&gt;&#xD;&#xA;        &lt;div class=&#34;person&#34;&gt;&#xD;&#xA;        &lt;td&gt;&lt;img src=&#34;https://calm-workshop-2024.github.io/panellist5_chelsea.jpeg&#34;&gt;&lt;/td&gt;&#xD;&#xA;        &lt;td&gt;&lt;a href=&#34;https://ai.stanford.edu/~cbfinn/&#34;&gt;Chelsea Finn&lt;br&gt;(Stanford University)&lt;/a&gt;&lt;/td&gt;&#xD;&#xA;    &lt;/div&gt;&#xD;&#xA;    &lt;div class=&#34;person&#34;&gt;&#xD;&#xA;        &lt;td&gt;&lt;img src=&#34;https://calm-workshop-2024.github.io/panellist6_zhijing.png&#34;&gt;&lt;/td&gt;&#xD;&#xA;        &lt;td&gt;&lt;a href=&#34;https://zhijing-jin.com/fantasy/&#34;&gt;Zhijing Jin&lt;br&gt;(Max Planck Institute &amp; ETH)&lt;/a&gt;&lt;/td&gt;&#xD;&#xA;    &lt;/div&gt;&#xD;&#xA;&lt;/div&gt;</description>
    </item>
    <item>
      <title>Organisers</title>
      <link>https://calm-workshop-2024.github.io/team/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://calm-workshop-2024.github.io/team/</guid>
      <description>&lt;h1 id=&#34;organisers&#34;&gt;Organisers&lt;/h1&gt;&#xA;&lt;div class=&#34;list-of-people&#34;&gt;&#xD;&#xA;    &lt;div class=&#34;person&#34;&gt;&#xD;&#xA;        &lt;td&gt;&lt;img src=&#34;https://calm-workshop-2024.github.io/organizer_felix.jpeg&#34;&gt;&lt;/td&gt;&#xD;&#xA;        &lt;td&gt;&lt;a href=&#34;https://felixludos.com/&#34;&gt;Felix Leeb &lt;br&gt;(Max Planck Institute for Intelligent Systems)&lt;/a&gt;&lt;/td&gt;&#xD;&#xA;    &lt;/div&gt;&#xD;&#xA;    &lt;div class=&#34;person&#34;&gt;&#xD;&#xA;        &lt;td&gt;&lt;img src=&#34;https://calm-workshop-2024.github.io/organizer_ching_lam.jpeg&#34;&gt;&lt;/td&gt;&#xD;&#xA;        &lt;td&gt;&lt;a href=&#34;https://chinglamchoi.github.io/cchoi/&#34;&gt;Ching Lam Choi&lt;br&gt;(MIT EECS)&lt;/a&gt;&lt;/td&gt;&#xD;&#xA;    &lt;/div&gt;&#xD;&#xA;    &lt;div class=&#34;person&#34;&gt;&#xD;&#xA;        &lt;td&gt;&lt;img src=&#34;https://calm-workshop-2024.github.io/organizer_luigi.jpeg&#34;&gt;&lt;/td&gt;&#xD;&#xA;        &lt;td&gt;&lt;a href=&#34;https://lgresele.github.io/&#34;&gt;Luigi Gresele&lt;br&gt;(University of Copenhagen)&lt;/a&gt;&lt;/td&gt;&#xD;&#xA;    &lt;/div&gt;&#xD;&#xA;    &lt;div class=&#34;person&#34;&gt;&#xD;&#xA;        &lt;td&gt;&lt;img src=&#34;https://calm-workshop-2024.github.io/organizer_andrei.jpeg&#34;&gt;&lt;/td&gt;&#xD;&#xA;        &lt;td&gt;&lt;a href=&#34;https://andreinicolicioiu.github.io/&#34;&gt;Andrei Nicolicioiu &lt;br&gt;(Mila and Université de Montréal)&lt;/a&gt;&lt;/td&gt;&#xD;&#xA;    &lt;/div&gt;&#xD;&#xA;    &lt;div class=&#34;person&#34;&gt;&#xD;&#xA;        &lt;td&gt;&lt;img src=&#34;https://calm-workshop-2024.github.io/organizer_xiusi.jpeg&#34;&gt;&lt;/td&gt;&#xD;&#xA;        &lt;td&gt;&lt;a href=&#34;https://lixiusi.github.io/&#34;&gt;Xiusi Li&lt;br&gt;(Mila and McGill University)&lt;/a&gt;&lt;/td&gt;&#xD;&#xA;    &lt;/div&gt;&#xD;&#xA;    &lt;div class=&#34;person&#34;&gt;&#xD;&#xA;        &lt;td&gt;&lt;img src=&#34;https://calm-workshop-2024.github.io/organizer_sophie.jpeg&#34;&gt;&lt;/td&gt;&#xD;&#xA;        &lt;td&gt;&lt;a href=&#34;https://scholar.google.co.uk/citations?user=9TQM9k4AAAAJ&amp;hl=en&#34;&gt;Sophie Xhonneux &lt;br&gt;(Mila and Université de Montréal)&lt;/a&gt;&lt;/td&gt;&#xD;&#xA;    &lt;/div&gt;&#xD;&#xA;    &lt;div class=&#34;person&#34;&gt;&#xD;&#xA;        &lt;td&gt;&lt;img src=&#34;https://calm-workshop-2024.github.io/organizer_patrik.jpeg&#34;&gt;&lt;/td&gt;&#xD;&#xA;        &lt;td&gt;&lt;a href=&#34;https://rpatrik96.github.io/&#34;&gt;Patrik Reizinger&lt;br&gt;(Max Planck Institute for Intelligent Systems)&lt;/a&gt;&lt;/td&gt;&#xD;&#xA;    &lt;/div&gt;&#xD;&#xA;    &lt;div class=&#34;person&#34;&gt;&#xD;&#xA;        &lt;td&gt;&lt;img src=&#34;https://calm-workshop-2024.github.io/organizer_josef.jpeg&#34;&gt;&lt;/td&gt;&#xD;&#xA;        &lt;td&gt;&lt;a href=&#34;https://valvoda.github.io/&#34;&gt;Josef Valvoda &lt;br&gt;(University of Copenhagen)&lt;/a&gt;&lt;/td&gt;&#xD;&#xA;    &lt;/div&gt;&#xD;&#xA;    &lt;div class=&#34;person&#34;&gt;&#xD;&#xA;        &lt;td&gt;&lt;img src=&#34;https://calm-workshop-2024.github.io/organizer_haoxuan.jpeg&#34;&gt;&lt;/td&gt;&#xD;&#xA;        &lt;td&gt;&lt;a href=&#34;https://scholar.google.com/citations?user=gtDqiucAAAAJ&amp;hl=en&#34;&gt;Haoxuan Li&lt;br&gt;(Peking University)&lt;/a&gt;&lt;/td&gt;&#xD;&#xA;    &lt;/div&gt;&#xD;&#xA;    &lt;div class=&#34;person&#34;&gt;&#xD;&#xA;        &lt;td&gt;&lt;img src=&#34;https://calm-workshop-2024.github.io/organizer_mengyue.webp&#34;&gt;&lt;/td&gt;&#xD;&#xA;        &lt;td&gt;&lt;a href=&#34;https://ymy4323460.github.io/&#34;&gt;Mengyue Yang &lt;br&gt;(University of College London)&lt;/a&gt;&lt;/td&gt;&#xD;&#xA;    &lt;/div&gt;&#xD;&#xA;    &lt;div class=&#34;person&#34;&gt;&#xD;&#xA;        &lt;td&gt;&lt;img src=&#34;https://calm-workshop-2024.github.io/organizer_dhanya.webp&#34;&gt;&lt;/td&gt;&#xD;&#xA;        &lt;td&gt;&lt;a href=&#34;https://www.dsridhar.com/&#34;&gt;Dhanya Sridhar&lt;br&gt;(Université de Montréal &amp; Mila)&lt;/a&gt;&lt;/td&gt;&#xD;&#xA;    &lt;/div&gt;&#xD;&#xA;    &lt;div class=&#34;person&#34;&gt;&#xD;&#xA;        &lt;td&gt;&lt;img src=&#34;https://calm-workshop-2024.github.io/bernhard.jpg&#34;&gt;&lt;/td&gt;&#xD;&#xA;        &lt;td&gt;&lt;a href=&#34;https://is.mpg.de/~bs&#34;&gt;Bernhard Schölkopf &lt;br&gt;(Max Planck Institute for Intelligent Systems &amp; ELLIS Institute Tübingen)&lt;/a&gt;&lt;/td&gt;&#xD;&#xA;    &lt;/div&gt;&#xD;&#xA;&lt;/div&gt;&#xD;&#xA;&lt;p id=&#34;reviewers&#34;&gt;&#xD;&#xA;&lt;h1 id=&#34;reviewers&#34;&gt;Reviewers&lt;/h1&gt;&#xA;&lt;p&gt;We have recruited a diverse group of great reviewers to help us evaluate the submissions to the workshop. We are grateful for their time and expertise.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Schedule and Format</title>
      <link>https://calm-workshop-2024.github.io/schedule/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://calm-workshop-2024.github.io/schedule/</guid>
      <description>&lt;h1 id=&#34;workshop-schedule--format&#34;&gt;Workshop Schedule &amp;amp; Format&lt;/h1&gt;&#xA;&lt;p&gt;The workshop will take place in &lt;strong&gt;East Exhibition Hall C&lt;/strong&gt; of the Vancouver Convention Centre on &lt;strong&gt;December 14, 2024&lt;/strong&gt;. The workshop will be a hybrid event, with both in-person and virtual participation. The schedule is as follows:&lt;/p&gt;&#xA;&lt;div style=&#34;width: 100%; font-size: smaller; text-align: center; margin-bottom: 18px; margin-top: 18px;&#34;&gt;&#xD;&#xA;    Legend:&#xD;&#xA;    &lt;span class=&#34;invited&#34;&gt;invited&lt;/span&gt; · &#xD;&#xA;    &lt;span class=&#34;break&#34;&gt;break&lt;/span&gt; · &#xD;&#xA;    &lt;span class=&#34;contributed&#34;&gt;contributed&lt;/span&gt; · &#xD;&#xA;    &lt;span class=&#34;poster&#34;&gt;poster&lt;/span&gt; ·&#xD;&#xA;    &lt;span class=&#34;panel&#34;&gt;panel&lt;/span&gt;&#xD;&#xA;&lt;/div&gt;&#xD;&#xA;&lt;table class=&#34;schedule&#34;&gt;&#xD;&#xA;    &lt;tr&gt;&#xD;&#xA;        &lt;th style=&#34;width:25%&#34;&gt;Time&lt;/th&gt;&#xD;&#xA;        &lt;th&gt;Program&lt;/th&gt;&#xD;&#xA;        &lt;th style=&#34;width:20%&#34;&gt;Format&lt;/th&gt;&#xD;&#xA;    &lt;/tr&gt;&#xD;&#xA;    &lt;tr&gt;&#xD;&#xA;        &lt;td&gt;08:45 - 09:00&lt;/td&gt;&#xD;&#xA;        &lt;td&gt;Opening remarks&lt;/td&gt;&#xD;&#xA;        &lt;td&gt;In-person&lt;/td&gt;&#xD;&#xA;    &lt;/tr&gt;&#xD;&#xA;    &lt;tr class=&#34;invited&#34;&gt;&#xD;&#xA;        &lt;td&gt;09:00 - 09:30&lt;/td&gt;&#xD;&#xA;        &lt;td&gt;Amit Sharma - &lt;small&gt;Teaching causal reasoning to language models&lt;/small&gt;&lt;/td&gt;&#xD;&#xA;        &lt;td&gt;In-person&lt;/td&gt;&#xD;&#xA;    &lt;/tr&gt;&#xD;&#xA;    &lt;tr class=&#34;invited&#34;&gt;&#xD;&#xA;        &lt;td&gt;09:30 - 10:00&lt;/td&gt;&#xD;&#xA;        &lt;td&gt;Jane X. Wang - &lt;small&gt;Causal reasoning in foundation agents&lt;/small&gt;&lt;/td&gt;&#xD;&#xA;        &lt;td&gt;In-person&lt;/td&gt;&#xD;&#xA;    &lt;/tr&gt;&#xD;&#xA;    &lt;tr class=&#34;break&#34;&gt;&#xD;&#xA;        &lt;td&gt;10:00 - 10:30&lt;/td&gt;&#xD;&#xA;        &lt;td&gt;Coffee break&lt;/td&gt;&#xD;&#xA;        &lt;td&gt;-&lt;/td&gt;&#xD;&#xA;    &lt;/tr&gt;&#xD;&#xA;    &lt;tr class=&#34;invited&#34;&gt;&#xD;&#xA;        &lt;td&gt;10:30 - 11:00&lt;/td&gt;&#xD;&#xA;        &lt;td&gt;Elias Bareinboim - TBD&lt;/td&gt;&#xD;&#xA;        &lt;td&gt;In-person&lt;/td&gt;&#xD;&#xA;    &lt;/tr&gt;&#xD;&#xA;    &lt;tr class=&#34;contributed&#34;&gt;&#xD;&#xA;        &lt;td&gt;11:00 - 11:15&lt;/td&gt;&#xD;&#xA;        &lt;td&gt;&lt;small&gt;From Causal to Concept-Based Representation Learning&lt;/small&gt;&lt;/td&gt;&#xD;&#xA;        &lt;td&gt;In-person&lt;/td&gt;&#xD;&#xA;    &lt;/tr&gt;&#xD;&#xA;    &lt;tr class=&#34;contributed&#34;&gt;&#xD;&#xA;        &lt;td&gt;11:15 - 11:30&lt;/td&gt;&#xD;&#xA;        &lt;td&gt;&lt;small&gt;Causal Order: The Key to Leveraging Imperfect Experts in Causal Inference&lt;/small&gt;&lt;/td&gt;&#xD;&#xA;        &lt;td&gt;In-person&lt;/td&gt;&#xD;&#xA;    &lt;/tr&gt;&#xD;&#xA;    &lt;tr class=&#34;poster&#34;&gt;&#xD;&#xA;        &lt;td&gt;11:30 - 12:00&lt;/td&gt;&#xD;&#xA;        &lt;td&gt;Poster session 1&lt;/td&gt;&#xD;&#xA;        &lt;td&gt;In-person&lt;/td&gt;&#xD;&#xA;    &lt;/tr&gt;&#xD;&#xA;    &lt;tr class=&#34;break&#34;&gt;&#xD;&#xA;        &lt;td&gt;12:00 - 13:30&lt;/td&gt;&#xD;&#xA;        &lt;td&gt;Lunch break&lt;/td&gt;&#xD;&#xA;        &lt;td&gt;Individually&lt;/td&gt;&#xD;&#xA;    &lt;/tr&gt;&#xD;&#xA;    &lt;tr class=&#34;invited&#34;&gt;&#xD;&#xA;        &lt;td&gt;13:30 - 14:00&lt;/td&gt;&#xD;&#xA;        &lt;td&gt;Victor Veitch - TBD&lt;/td&gt;&#xD;&#xA;        &lt;td&gt;In-person&lt;/td&gt;&#xD;&#xA;    &lt;/tr&gt;&#xD;&#xA;    &lt;tr class=&#34;contributed&#34;&gt;&#xD;&#xA;        &lt;td&gt;14:00 - 14:15&lt;/td&gt;&#xD;&#xA;        &lt;td&gt;&lt;small&gt;Using Relational and Causality Context for Tasks with Specialized Vocabularies that are Challenging for LLMs&lt;/small&gt;&lt;/td&gt;&#xD;&#xA;        &lt;td&gt;In-person&lt;/td&gt;&#xD;&#xA;    &lt;/tr&gt;&#xD;&#xA;    &lt;tr class=&#34;contributed&#34;&gt;&#xD;&#xA;        &lt;td&gt;14:15 - 14:30&lt;/td&gt;&#xD;&#xA;        &lt;td&gt;&lt;small&gt;Causally Testing Gender Bias in LLMs: A Case Study on Occupational Bias&lt;/small&gt;&lt;/td&gt;&#xD;&#xA;        &lt;td&gt;In-person&lt;/td&gt;&#xD;&#xA;    &lt;/tr&gt;&#xD;&#xA;    &lt;tr class=&#34;poster&#34;&gt;&#xD;&#xA;        &lt;td&gt;14:30 - 15:00&lt;/td&gt;&#xD;&#xA;        &lt;td&gt;Poster session 2&lt;/td&gt;&#xD;&#xA;        &lt;td&gt;In-person&lt;/td&gt;&#xD;&#xA;    &lt;/tr&gt;&#xD;&#xA;    &lt;tr class=&#34;break&#34;&gt;&#xD;&#xA;        &lt;td&gt;15:00 - 15:30&lt;/td&gt;&#xD;&#xA;        &lt;td&gt;Coffee break&lt;/td&gt;&#xD;&#xA;        &lt;td&gt;-&lt;/td&gt;&#xD;&#xA;    &lt;/tr&gt;&#xD;&#xA;    &lt;tr class=&#34;invited&#34;&gt;&#xD;&#xA;        &lt;td&gt;15:30 - 16:00&lt;/td&gt;&#xD;&#xA;        &lt;td&gt;Claudia Shi - &lt;small&gt;Hypothesis testing the circuit hypothesis in LLMs&lt;/small&gt;&lt;/td&gt;&#xD;&#xA;        &lt;td&gt;In-person&lt;/td&gt;&#xD;&#xA;    &lt;/tr&gt;&#xD;&#xA;    &lt;tr class=&#34;invited&#34;&gt;&#xD;&#xA;        &lt;td&gt;16:00 - 16:30&lt;/td&gt;&#xD;&#xA;        &lt;td&gt;Tobias Gerstenberg - &lt;small&gt;Causal thinking in humans and machines&lt;/small&gt;&lt;/td&gt;&#xD;&#xA;        &lt;td&gt;In-person&lt;/td&gt;&#xD;&#xA;    &lt;/tr&gt;&#xD;&#xA;    &lt;tr class=&#34;panel&#34;&gt;&#xD;&#xA;        &lt;td&gt;16:30 - 17:30&lt;/td&gt;&#xD;&#xA;        &lt;td&gt;Panel discussion: Maria Antoniak, Elias Bareinboim, Chelsea Finn, Atticus Geiger, Zhijing Jin, Giambattista Parascandolo&lt;/td&gt;&#xD;&#xA;        &lt;td&gt;In-person&lt;/td&gt;&#xD;&#xA;    &lt;/tr&gt;&#xD;&#xA;    &lt;tr&gt;&#xD;&#xA;        &lt;td&gt;17:30&lt;/td&gt;&#xD;&#xA;        &lt;td&gt;Closing remarks and Best Paper Award!&lt;/td&gt;&#xD;&#xA;        &lt;td&gt;In-person&lt;/td&gt;&#xD;&#xA;    &lt;/tr&gt;&#xD;&#xA;&lt;/table&gt;&#xD;&#xA;&lt;div style=&#34;width: 100%; font-size: smaller; text-align: center; margin-top: 18px;&#34;&gt;&#xD;&#xA;    &lt;em&gt;All times local to Vancouver, Canada - Pacific Standard Time (PST)&lt;/em&gt;&#xD;&#xA;&lt;/div&gt;&#xD;&#xA;&lt;p&gt;All talks will be recorded and made available to registered participants after the workshop through the NeurIPS website.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Slides and Recording</title>
      <link>https://calm-workshop-2024.github.io/slides-recording/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://calm-workshop-2024.github.io/slides-recording/</guid>
      <description>&lt;h1 id=&#34;slides&#34;&gt;Slides&lt;/h1&gt;&#xA;&lt;!-- Slides from the speakers can be downloaded at the links below.&#xD;&#xA;&#xD;&#xA;* [Aapo Hyvärinen, &#34;Causal Discovery and Latent-Variable Models&#34;](https://github.com/CRL-UAI-2022/crl-uai-2022.github.io/raw/main/slides/Hyvarinen.pdf)&#xD;&#xA;* [Sebastien Lachapelle, &#34;Partial Disentanglement via Mechanism Sparsity&#34;](https://github.com/CRL-UAI-2022/crl-uai-2022.github.io/raw/main/slides/lachapelle.pptx)&#xD;&#xA;* [Patrik Reizinger, &#34;Multivariate Causal Discovery with General Nonlinear Relationships&#34;](https://github.com/CRL-UAI-2022/crl-uai-2022.github.io/raw/main/slides/reizinger.pdf)&#xD;&#xA;* [Phillip Lippe, &#34;Learning Causal Variables from Temporal Sequences with Interventions&#34;](https://github.com/CRL-UAI-2022/crl-uai-2022.github.io/raw/main/slides/Lippe.pdf)&#xD;&#xA;* [Anirudh Goyal, &#34;From Specialists to Generalists&#34;](https://github.com/CRL-UAI-2022/crl-uai-2022.github.io/raw/main/slides/Goyal.pdf)&#xD;&#xA;* [Sander Beckers, &#34;Causal Abstractions and Causal Representation Learning&#34;](https://github.com/CRL-UAI-2022/crl-uai-2022.github.io/raw/main/slides/beckers.pdf)&#xD;&#xA;* [Caroline Uhler, &#34;Causal Imputation&#34;](https://github.com/CRL-UAI-2022/crl-uai-2022.github.io/raw/main/slides/Uhler.pdf)&#xD;&#xA;* [Fabio Massimo Zennaro, &#34;Abstraction between Structural Causal Models: A Review of Definitions and Properties&#34;](https://github.com/CRL-UAI-2022/crl-uai-2022.github.io/raw/main/slides/zennaro.pdf)&#xD;&#xA;* [Yiping Wang, &#34;Causal Class Activation Map for Weakly-Supervised Semantic Segmentation&#34;](https://github.com/CRL-UAI-2022/crl-uai-2022.github.io/raw/main/slides/wang.pdf)&#xD;&#xA;* Bernhard Schölkopf, &#34;Desiderata for Causal Representations&#34;&#xD;&#xA;* [Gemma Moran, &#34;Identifiable Deep Generative Models via Sparse Decoding&#34;](https://github.com/CRL-UAI-2022/crl-uai-2022.github.io/raw/main/slides/moran.pdf)&#xD;&#xA;&#xD;&#xA;# Recording&#xD;&#xA;&#xD;&#xA;This is a recording of talks that took place in the second part of the workshop (after the lunch break); recordings of the first part of the workshop are unfortunately not available.&#xD;&#xA;&#xD;&#xA;&lt;div style=&#34;position: relative; padding-bottom: 66.25%; height: 0; overflow: hidden;&#34;&gt;&#xD;&#xA;  &lt;iframe src=&#34;https://www.youtube.com/embed/kSwURlFarzE&#34; style=&#34;position: absolute; top: 0; left: 0; width: 100%; height: 100%; border:0;&#34; allowfullscreen title=&#34;Recording of the Workshop (Second Part)&#34;&gt;&lt;/iframe&gt;&#xD;&#xA;&lt;/div&gt; --&gt;</description>
    </item>
  </channel>
</rss>
